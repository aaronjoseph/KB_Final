{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_AutoML.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "1UkrFEi5Xw0W9OivC5mgY7TVK-RqK8IY3",
      "authorship_tag": "ABX9TyPJcyMIn3mdwUCiJoXOAAEh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaronjoseph/KB_Final/blob/master/4_AutoML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wzzvv1BjMs2w",
        "outputId": "816d6951-4343-4a74-8b49-2b07038e929a"
      },
      "source": [
        "! pip install mlflow\r\n",
        "#Load the libraries\r\n",
        "from mlflow import log_metric, log_param, log_artifacts\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import nltk\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn.preprocessing import LabelBinarizer\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem.porter import PorterStemmer\r\n",
        "from wordcloud import WordCloud,STOPWORDS\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "import spacy\r\n",
        "import re,string,unicodedata\r\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\r\n",
        "from nltk.stem import LancasterStemmer,WordNetLemmatizer\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.svm import SVC\r\n",
        "from textblob import TextBlob\r\n",
        "from textblob import Word\r\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\r\n",
        "import os\r\n",
        "from tqdm import tqdm\r\n",
        "import collections, numpy\r\n",
        "from xgboost import XGBClassifier\r\n",
        "from lightgbm import LGBMClassifier\r\n",
        "tqdm.pandas()\r\n",
        "from sklearn.model_selection import train_test_split,KFold\r\n",
        "nltk.download('stopwords')\r\n",
        "! pip install neptune-client==0.4.132\r\n",
        "import neptune\r\n",
        "neptune.init(\r\n",
        "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5haSIsImFwaV91cmwiOiJodHRwczovL3VpLm5lcHR1bmUuYWkiLCJhcGlfa2V5IjoiOGI1M2QwMmItZGQyMi00MTBmLThhZTktZDY0OThjYmZlMGMyIn0=\",\r\n",
        "    project_qualified_name=\"aaronjosephmathew/sandbox\"\r\n",
        ")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.6/dist-packages (1.13.1)\n",
            "Requirement already satisfied: azure-storage-blob>=12.0.0 in /usr/local/lib/python3.6/dist-packages (from mlflow) (12.7.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from mlflow) (7.1.2)\n",
            "Requirement already satisfied: alembic<=1.4.1 in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.4.1)\n",
            "Requirement already satisfied: prometheus-flask-exporter in /usr/local/lib/python3.6/dist-packages (from mlflow) (0.18.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.3.0)\n",
            "Requirement already satisfied: docker>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from mlflow) (4.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.1.5)\n",
            "Requirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.6/dist-packages (from mlflow) (2.23.0)\n",
            "Requirement already satisfied: querystring-parser in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.2.4)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from mlflow) (0.4.1)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.3.22)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from mlflow) (3.12.4)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.1.2)\n",
            "Requirement already satisfied: gitpython>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from mlflow) (3.1.12)\n",
            "Requirement already satisfied: databricks-cli>=0.8.7 in /usr/local/lib/python3.6/dist-packages (from mlflow) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from mlflow) (2.8.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from mlflow) (0.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from mlflow) (3.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.19.5)\n",
            "Requirement already satisfied: gunicorn; platform_system != \"Windows\" in /usr/local/lib/python3.6/dist-packages (from mlflow) (20.0.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.15.0)\n",
            "Requirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from azure-storage-blob>=12.0.0->mlflow) (3.3.1)\n",
            "Requirement already satisfied: msrest>=0.6.18 in /usr/local/lib/python3.6/dist-packages (from azure-storage-blob>=12.0.0->mlflow) (0.6.21)\n",
            "Requirement already satisfied: azure-core<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from azure-storage-blob>=12.0.0->mlflow) (1.10.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.6/dist-packages (from alembic<=1.4.1->mlflow) (1.1.4)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.6/dist-packages (from alembic<=1.4.1->mlflow) (1.0.4)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.6/dist-packages (from prometheus-flask-exporter->mlflow) (0.9.0)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.6/dist-packages (from docker>=4.0.0->mlflow) (0.57.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->mlflow) (2018.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (2020.12.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.0->mlflow) (51.3.3)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow) (2.11.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow) (1.1.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from gitpython>=2.1.0->mlflow) (4.0.5)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from databricks-cli>=0.8.7->mlflow) (0.8.7)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.1.4->azure-storage-blob>=12.0.0->mlflow) (1.14.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.6.18->azure-storage-blob>=12.0.0->mlflow) (1.3.0)\n",
            "Requirement already satisfied: isodate>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.6.18->azure-storage-blob>=12.0.0->mlflow) (0.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic<=1.4.1->mlflow) (1.1.1)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow) (3.0.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.0.0->mlflow) (2.20)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-storage-blob>=12.0.0->mlflow) (3.1.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Requirement already satisfied: neptune-client==0.4.132 in /usr/local/lib/python3.6/dist-packages (0.4.132)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from neptune-client==0.4.132) (7.1.2)\n",
            "Requirement already satisfied: oauthlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from neptune-client==0.4.132) (3.1.0)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from neptune-client==0.4.132) (0.18.2)\n",
            "Requirement already satisfied: Pillow>=1.1.6 in /usr/local/lib/python3.6/dist-packages (from neptune-client==0.4.132) (7.0.0)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from neptune-client==0.4.132) (2.23.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from neptune-client==0.4.132) (1.15.0)\n",
            "Requirement already satisfied: websocket-client>=0.35.0 in /usr/local/lib/python3.6/dist-packages (from neptune-client==0.4.132) (0.57.0)\n",
            "Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from neptune-client==0.4.132) (1.3.0)\n",
            "Requirement already satisfied: GitPython>=2.0.8 in /usr/local/lib/python3.6/dist-packages (from neptune-client==0.4.132) (3.1.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from neptune-client==0.4.132) (20.8)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.6/dist-packages (from neptune-client==0.4.132) (2.0.1)\n",
            "Requirement already satisfied: bravado in /usr/local/lib/python3.6/dist-packages (from neptune-client==0.4.132) (11.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from neptune-client==0.4.132) (1.1.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->neptune-client==0.4.132) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->neptune-client==0.4.132) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->neptune-client==0.4.132) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->neptune-client==0.4.132) (1.24.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython>=2.0.8->neptune-client==0.4.132) (4.0.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->neptune-client==0.4.132) (2.4.7)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.6/dist-packages (from bravado->neptune-client==0.4.132) (3.17.2)\n",
            "Requirement already satisfied: monotonic in /usr/local/lib/python3.6/dist-packages (from bravado->neptune-client==0.4.132) (1.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from bravado->neptune-client==0.4.132) (3.7.4.3)\n",
            "Requirement already satisfied: bravado-core>=5.16.1 in /usr/local/lib/python3.6/dist-packages (from bravado->neptune-client==0.4.132) (5.17.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from bravado->neptune-client==0.4.132) (2.8.1)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.6/dist-packages (from bravado->neptune-client==0.4.132) (1.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from bravado->neptune-client==0.4.132) (3.13)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->neptune-client==0.4.132) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas->neptune-client==0.4.132) (1.19.5)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython>=2.0.8->neptune-client==0.4.132) (3.0.5)\n",
            "Requirement already satisfied: jsonref in /usr/local/lib/python3.6/dist-packages (from bravado-core>=5.16.1->bravado->neptune-client==0.4.132) (0.2)\n",
            "Requirement already satisfied: swagger-spec-validator>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from bravado-core>=5.16.1->bravado->neptune-client==0.4.132) (2.7.3)\n",
            "Requirement already satisfied: jsonschema[format]>=2.5.1 in /usr/local/lib/python3.6/dist-packages (from bravado-core>=5.16.1->bravado->neptune-client==0.4.132) (2.6.0)\n",
            "Requirement already satisfied: strict-rfc3339; extra == \"format\" in /usr/local/lib/python3.6/dist-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune-client==0.4.132) (0.7)\n",
            "Requirement already satisfied: webcolors; extra == \"format\" in /usr/local/lib/python3.6/dist-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune-client==0.4.132) (1.11.1)\n",
            "Requirement already satisfied: rfc3987; extra == \"format\" in /usr/local/lib/python3.6/dist-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune-client==0.4.132) (1.3.8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Project(aaronjosephmathew/sandbox)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fhm3yJynN5gk"
      },
      "source": [
        "sentiment_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/training.1600000.processed.noemoticon.csv',header=None,error_bad_lines=False,engine='python')\r\n",
        "sentiment_data = sentiment_data.sample(n=1_00_000,replace=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkZzieW5N5m-"
      },
      "source": [
        "# Data Cleaning Process\r\n",
        "def preprocess(text):\r\n",
        "  text=text.lower()\r\n",
        "  # remove hyperlinks\r\n",
        "  text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\r\n",
        "  text = re.sub(r'http?:\\/\\/.*[\\r\\n]*', '', text)\r\n",
        "  #remove hashtag sign\r\n",
        "  text=re.sub(r\"#\",\"\",text)   \r\n",
        "  #remove mentions\r\n",
        "  text = re.sub(r\"(?:\\@)\\w+\", '', text)\r\n",
        "  #remove non ascii chars\r\n",
        "  text=text.encode(\"ascii\",errors=\"ignore\").decode()\r\n",
        "  #remove some puncts (except . ! ?)\r\n",
        "  text=re.sub(r'[:\"#$%&\\*+,-/:;<=>@\\\\^_`{|}~]+','',text)\r\n",
        "  text=re.sub(r'[!]+','!',text)\r\n",
        "  text=re.sub(r'[?]+','?',text)\r\n",
        "  text=re.sub(r'[.]+','.',text)\r\n",
        "  text=re.sub(r\"'\",\"\",text)\r\n",
        "  text=re.sub(r\"\\(\",\"\",text)\r\n",
        "  text=re.sub(r\"\\)\",\"\",text)    \r\n",
        "  text=\" \".join(text.split())\r\n",
        "  return text\r\n",
        "\r\n",
        "def simple_stemmer(text):\r\n",
        "  ps=nltk.porter.PorterStemmer()\r\n",
        "  text= ' '.join([ps.stem(word) for word in text.split()])\r\n",
        "  return text\r\n",
        "\r\n",
        "#removing the stopwords\r\n",
        "def remove_stopwords(text, is_lower_case=False):\r\n",
        "  #set stopwords to english\r\n",
        "  stop=set(stopwords.words('english'))\r\n",
        "  # Tokenization\r\n",
        "  tokenizer=ToktokTokenizer()\r\n",
        "  #Setting English stopwords\r\n",
        "  stopword_list=nltk.corpus.stopwords.words('english')\r\n",
        "  tokens = tokenizer.tokenize(text)\r\n",
        "  tokens = [token.strip() for token in tokens]\r\n",
        "  if is_lower_case:\r\n",
        "      filtered_tokens = [token for token in tokens if token not in stopword_list]\r\n",
        "  else:\r\n",
        "      filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\r\n",
        "  filtered_text = ' '.join(filtered_tokens)    \r\n",
        "  return filtered_text"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8VBmhmzN5rn",
        "outputId": "5019f3bd-ff01-4877-bd4d-39648f7d5191"
      },
      "source": [
        "#Apply function\r\n",
        "sentiment_data['clean']=sentiment_data[5].progress_apply(preprocess)\r\n",
        "sentiment_data['stem']=sentiment_data['clean'].progress_apply(simple_stemmer)\r\n",
        "sentiment_data['token'] = sentiment_data['stem'].progress_apply(remove_stopwords) "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [00:02<00:00, 46390.77it/s]\n",
            "100%|██████████| 100000/100000 [00:21<00:00, 4633.92it/s]\n",
            "100%|██████████| 100000/100000 [00:32<00:00, 3031.93it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBWjnS0v4Ify"
      },
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, auc, roc_curve, accuracy_score\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBtTXjUBN5zz"
      },
      "source": [
        "le = LabelEncoder()\r\n",
        "sentiment_data['output'] = le.fit_transform(sentiment_data[0])\r\n",
        "# Splitting the data - Into train_test\r\n",
        "X = sentiment_data['token']\r\n",
        "y = sentiment_data['output']\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42) "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT4bvu1o5HZl"
      },
      "source": [
        "# Count Vectorizer for Bag of words\r\n",
        "cv=CountVectorizer(min_df=0,max_df=1,binary=False,ngram_range=(1,3))\r\n",
        "#transformed train reviews\r\n",
        "cv_train_reviews=cv.fit_transform(X_train)\r\n",
        "#transformed test reviews\r\n",
        "cv_test_reviews=cv.transform(X_test)\r\n",
        "# TFIDF\r\n",
        "tv=TfidfVectorizer(min_df=0,max_df=1,use_idf=True,ngram_range=(1,3))\r\n",
        "#transformed train reviews\r\n",
        "tv_train_reviews=tv.fit_transform(X_train)\r\n",
        "#transformed test reviews\r\n",
        "tv_test_reviews=tv.transform(X_test)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRMPQaylrqps",
        "outputId": "846e3bf8-801a-4341-de64-850cf05355a1"
      },
      "source": [
        "cv_train_reviews"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<80000x675680 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 675680 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptCsCWhTaKiB"
      },
      "source": [
        "### Reference Data\r\n",
        "\r\n",
        "Train Data | Test Data\r\n",
        "---| ---\r\n",
        "Count Vectorizer Data\r\n",
        "cv_train_reviews | y_train\r\n",
        "cv_test_reviews | y_test\r\n",
        "TFIDF Data | \r\n",
        "tv_train_reviews | y_train\r\n",
        "tv_test_reviews | y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FY57FmXbFr9"
      },
      "source": [
        "AUTOML \r\n",
        "\r\n",
        "- PyCaret\r\n",
        "- H20 AutoML\r\n",
        "\r\n",
        "PyCaret is an open source, low-code machine learning library in Python that allows you to go from preparing your data to deploying your model within seconds in your choice of notebook environment.\r\n",
        "\r\n",
        "PyCaret being a low-code library makes you more productive. With less time spent coding, you and your team can now focus on business problems.\r\n",
        "\r\n",
        "PyCaret is simple and easy to use machine learning library that will help you to perform end-to-end ML experiments with less lines of code.\r\n",
        "\r\n",
        "PyCaret is a business ready solution. It allows you to do prototyping quickly and efficiently from your choice of notebook environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhR0JIKVtHD9",
        "outputId": "13d12fa8-bdbd-4745-a6c6-fab9fd53a54a"
      },
      "source": [
        "!pip install h2o"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting h2o\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/d1/9edb2359afa29049bb6e75f9a673bb68c897e7f3e6238ffb77ba9eddf04b/h2o-3.32.0.3.tar.gz (164.6MB)\n",
            "\u001b[K     |████████████████████████████████| 164.6MB 44kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from h2o) (2.23.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from h2o) (0.8.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from h2o) (0.18.2)\n",
            "Collecting colorama>=0.3.8\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (2.10)\n",
            "Building wheels for collected packages: h2o\n",
            "  Building wheel for h2o (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for h2o: filename=h2o-3.32.0.3-py2.py3-none-any.whl size=164649662 sha256=8b40cfe4fe1774b7d9a33c9f204679e2288202a8e5612e29673ce6b70194768a\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/fd/63/96d322a27867a81a2904172a75aed5241913d603a4b8c4b277\n",
            "Successfully built h2o\n",
            "Installing collected packages: colorama, h2o\n",
            "Successfully installed colorama-0.4.4 h2o-3.32.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RjPeXBMd90m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "outputId": "2ff5ecec-c45c-40a5-c2d4-5f32806d0eba"
      },
      "source": [
        "from h2o.automl import H2OAutoML\r\n",
        "import h2o\r\n",
        "h2o.init()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
            "Attempting to start a local H2O server...\n",
            "  Java Version: openjdk version \"11.0.9.1\" 2020-11-04; OpenJDK Runtime Environment (build 11.0.9.1+1-Ubuntu-0ubuntu1.18.04); OpenJDK 64-Bit Server VM (build 11.0.9.1+1-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n",
            "  Starting server from /usr/local/lib/python3.6/dist-packages/h2o/backend/bin/h2o.jar\n",
            "  Ice root: /tmp/tmpkxwooihs\n",
            "  JVM stdout: /tmp/tmpkxwooihs/h2o_unknownUser_started_from_python.out\n",
            "  JVM stderr: /tmp/tmpkxwooihs/h2o_unknownUser_started_from_python.err\n",
            "  Server is running at http://127.0.0.1:54321\n",
            "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>02 secs</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.32.0.3</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>1 month and 2 days </td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_unknownUser_xlwhx7</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>6.379 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>4</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>4</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>accepting new members, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://127.0.0.1:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>H2O_API_Extensions:</td>\n",
              "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.6.9 final</td></tr></table></div>"
            ],
            "text/plain": [
              "--------------------------  ------------------------------------------------------------------\n",
              "H2O_cluster_uptime:         02 secs\n",
              "H2O_cluster_timezone:       Etc/UTC\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.32.0.3\n",
              "H2O_cluster_version_age:    1 month and 2 days\n",
              "H2O_cluster_name:           H2O_from_python_unknownUser_xlwhx7\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    6.379 Gb\n",
              "H2O_cluster_total_cores:    4\n",
              "H2O_cluster_allowed_cores:  4\n",
              "H2O_cluster_status:         accepting new members, healthy\n",
              "H2O_connection_url:         http://127.0.0.1:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
              "H2O_internal_security:      False\n",
              "H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
              "Python_version:             3.6.9 final\n",
              "--------------------------  ------------------------------------------------------------------"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBEjHCgEPXWe"
      },
      "source": [
        "import scipy"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eTeXo9hScCE"
      },
      "source": [
        "scipy.sparse.csr_matrix.todense(cv_train_reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "Ac7Ri6GcvQE0",
        "outputId": "b95438ee-8a9c-4ae5-cc74-5704fbf8ccfa"
      },
      "source": [
        "x = h2o.H2OFrame(cv_train_reviews)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parse progress: |████████████████████████ (failed)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-061bf61ea440>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mH2OFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_train_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h2o/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, python_obj, destination_frame, header, separator, column_names, column_types, na_strings, skipped_columns)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpython_obj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             self._upload_python_object(python_obj, destination_frame, header, separator,\n\u001b[0;32m--> 109\u001b[0;31m                                        column_names, column_types, na_strings, skipped_columns)\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h2o/frame.py\u001b[0m in \u001b[0;36m_upload_python_object\u001b[0;34m(self, python_obj, destination_frame, header, separator, column_names, column_types, na_strings, skipped_columns)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0massert_is_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_ndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpandas_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscipy_sparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscipy_sparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upload_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdestination_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;31m# TODO: all these _handlers should really belong to this class, not to shared_utils.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h2o/frame.py\u001b[0m in \u001b[0;36m_upload_sparse_matrix\u001b[0;34m(self, matrix, destination_frame)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"source_frames\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrawkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"destination_frame\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdestination_frame\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mH2OJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST /3/ParseSVMLight\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Parse\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdestination_frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h2o/job.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, poll_updates)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"stacktrace\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 raise EnvironmentError(\"Job with key {} failed with an exception: {}\\nstacktrace: \"\n\u001b[0;32m---> 78\u001b[0;31m                                        \"\\n{}\".format(self.job_key, self.exception, self.job[\"stacktrace\"]))\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job with key %s failed with an exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Job with key $03017f00000132d4ffffffff$_a22674ac9fb422691501bb6058b74084 failed with an exception: DistributedException from /127.0.0.1:54321: 'Java heap space', caused by java.lang.OutOfMemoryError: Java heap space\nstacktrace: \nDistributedException from /127.0.0.1:54321: 'Java heap space', caused by java.lang.OutOfMemoryError: Java heap space\n\tat water.MRTask.getResult(MRTask.java:494)\n\tat water.MRTask.getResult(MRTask.java:502)\n\tat water.MRTask.doAll(MRTask.java:409)\n\tat water.parser.ParseDataset.parseAllKeys(ParseDataset.java:254)\n\tat water.parser.ParseDataset.access$000(ParseDataset.java:26)\n\tat water.parser.ParseDataset$1.compute2(ParseDataset.java:112)\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1575)\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "7BDJxAZtt5OF",
        "outputId": "99099717-3817-45e4-f11d-3fb230aa5be6"
      },
      "source": [
        "aml = H2OAutoML(nfolds=5,balance_classes=False, seed =42)\r\n",
        "aml.train(x = cv_train_reviews, y = y_train, training_frame=None, validation_frame=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-47ac62c13bce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0maml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH2OAutoML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnfolds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbalance_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_train_reviews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h2o/automl/autoh2o.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y, training_frame, fold_column, weights_column, validation_frame, leaderboard_frame, blending_frame)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \"\"\"\n\u001b[1;32m    405\u001b[0m         \u001b[0;31m# Minimal required arguments are training_frame and y (response)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mtraining_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH2OFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'training_frame'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequired\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training_frame'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h2o/frame.py\u001b[0m in \u001b[0;36m_validate\u001b[0;34m(param, name, required, message)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrequired\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 'training_frame' must be a valid H2OFrame!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYjceQ0F1Nuw"
      },
      "source": [
        "import logging\r\n",
        "import os\r\n",
        "# Logging configuration\r\n",
        "logger = logging.getLogger(__name__)\r\n",
        "# Level set to Debug\r\n",
        "logger.setLevel(logging.DEBUG)\r\n",
        "# Utilizing os module to find the current path and append the log name for the file name\r\n",
        "filename = os.path.join('/content/Data.log')\r\n",
        "# Mode & File Name defined\r\n",
        "fhandler = logging.FileHandler(filename=filename, mode='a')\r\n",
        "# Logging format for both log and stream handler\r\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\r\n",
        "fhandler.setFormatter(formatter)\r\n",
        "# Stream Handler\r\n",
        "stream_handler = logging.StreamHandler()\r\n",
        "stream_handler.setFormatter(formatter)\r\n",
        "# Log Handlers\r\n",
        "logger.addHandler(fhandler)\r\n",
        "logger.addHandler(stream_handler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPnDnmFT1N3f",
        "outputId": "5b33007d-6ca2-466f-a24a-f2311ce9911d"
      },
      "source": [
        "Model_Name = 'XGBoost'\r\n",
        "a_s = 98.8\r\n",
        "precision = 89\r\n",
        "recall = 81\r\n",
        "logger.debug(\"Model Name {}\".format(Model_Name))\r\n",
        "logger.debug(\"Accuracy Score {}\".format(a_s))\r\n",
        "logger.debug(\"Precision Score {}\".format(precision))\r\n",
        "logger.debug(\"Recall Score {}\".format(recall))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-25 06:14:54,342 - __main__ - DEBUG - Model Name XGBoost\n",
            "2021-01-25 06:14:54,344 - __main__ - DEBUG - Accuracy Score 98.8\n",
            "2021-01-25 06:14:54,345 - __main__ - DEBUG - Precision Score 89\n",
            "2021-01-25 06:14:54,346 - __main__ - DEBUG - Recall Score 81\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}