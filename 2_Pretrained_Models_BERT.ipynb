{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_Pretrained Models - BERT.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1sRIQsfakOtgjc6OITUrdL16tUFe_jFkp",
      "authorship_tag": "ABX9TyO71/AxK3OYCauYLQ2WE6L1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e8093e9097904a80b333ac8660bf8ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ca15aa74aed34494a003e075e0b563fe",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6a859e339aae4026ae78d3e217391b86",
              "IPY_MODEL_541be8d5999e49eb9a042f0db6ad9840"
            ]
          }
        },
        "ca15aa74aed34494a003e075e0b563fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a859e339aae4026ae78d3e217391b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f92fe93b671a424e8128677545b94a9a",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4ce0064975634ee5abd8cbaed76edac6"
          }
        },
        "541be8d5999e49eb9a042f0db6ad9840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_904be8f7f5d94124b73d85df97fbc635",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [1:45:10&lt;00:00, 6310.28s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a448870a16014eb19f52883018fbf676"
          }
        },
        "f92fe93b671a424e8128677545b94a9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4ce0064975634ee5abd8cbaed76edac6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "904be8f7f5d94124b73d85df97fbc635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a448870a16014eb19f52883018fbf676": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b79453e7bf224ffbbee0695ed6671f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2ceb9d8e716641cabcabf57aedc83be1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e03ede94e4be447f88be066ffd8024a1",
              "IPY_MODEL_5000ac9f1a9747629d554d2426f6df1f"
            ]
          }
        },
        "2ceb9d8e716641cabcabf57aedc83be1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e03ede94e4be447f88be066ffd8024a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ee10b5bbc9d445b0b98f1e84f177e968",
            "_dom_classes": [],
            "description": "Epoch 1: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 40000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 40000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9ebd7160f75a474da11326894afb0a50"
          }
        },
        "5000ac9f1a9747629d554d2426f6df1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a884708730b84e709d51cbb454bfa795",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 40000/40000 [1:38:38&lt;00:00,  6.66it/s, training_loss=0.139]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a8b2e67fdf14715bd325f7d7dce5be2"
          }
        },
        "ee10b5bbc9d445b0b98f1e84f177e968": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9ebd7160f75a474da11326894afb0a50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a884708730b84e709d51cbb454bfa795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a8b2e67fdf14715bd325f7d7dce5be2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaronjoseph/KB_Final/blob/master/2_Pretrained_Models_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Gxf8ay5zbub"
      },
      "source": [
        "# Main \r\n",
        "This codebase will demonstrate the following\r\n",
        "\r\n",
        "- Cleaning of the Sentiment 140 data ; tokenizing\r\n",
        "- Using pretrained model - RoBERTa to train on the data\r\n",
        "- Log the metrics over Neptune.ai\r\n",
        "- Save the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOH4QcNw8F1x"
      },
      "source": [
        "# Loading the libraries\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVOFSAdZ76Sa",
        "outputId": "4e3306ce-bc71-4f1a-f621-a4c760000ebe"
      },
      "source": [
        "# Tracking/Logging the data\r\n",
        "! pip install neptune-client==0.4.132\r\n",
        "! pip install transformers\r\n",
        "!pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html\r\n",
        "import neptune\r\n",
        "neptune.init(\r\n",
        "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5haSIsImFwaV91cmwiOiJodHRwczovL3VpLm5lcHR1bmUuYWkiLCJhcGlfa2V5IjoiOGI1M2QwMmItZGQyMi00MTBmLThhZTktZDY0OThjYmZlMGMyIn0=\",\r\n",
        "    project_qualified_name=\"aaronjosephmathew/sandbox\"\r\n",
        ")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: neptune-client==0.4.132 in /usr/local/lib/python3.6/dist-packages (0.4.132)\n",
            "Requirement already satisfied: websocket-client>=0.35.0 in /usr/local/lib/python3.6/dist-packages (from neptune-client==0.4.132) (0.57.0)\n",
            "Requirement already satisfied: oauthlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from neptune-client==0.4.132) (3.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from neptune-client==0.4.132) (1.15.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from neptune-client==0.4.132) (7.1.2)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.6/dist-packages (from neptune-client==0.4.132) (2.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from neptune-client==0.4.132) (20.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from neptune-client==0.4.132) (1.1.5)\n",
            "Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from neptune-client==0.4.132) (1.3.0)\n",
            "Requirement already satisfied: Pillow>=1.1.6 in /usr/local/lib/python3.6/dist-packages (from neptune-client==0.4.132) (7.0.0)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from neptune-client==0.4.132) (2.23.0)\n",
            "Requirement already satisfied: bravado in /usr/local/lib/python3.6/dist-packages (from neptune-client==0.4.132) (11.0.2)\n",
            "Requirement already satisfied: GitPython>=2.0.8 in /usr/local/lib/python3.6/dist-packages (from neptune-client==0.4.132) (3.1.12)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from neptune-client==0.4.132) (0.18.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->neptune-client==0.4.132) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->neptune-client==0.4.132) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas->neptune-client==0.4.132) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->neptune-client==0.4.132) (2018.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->neptune-client==0.4.132) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->neptune-client==0.4.132) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->neptune-client==0.4.132) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->neptune-client==0.4.132) (1.24.3)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.6/dist-packages (from bravado->neptune-client==0.4.132) (1.0.2)\n",
            "Requirement already satisfied: bravado-core>=5.16.1 in /usr/local/lib/python3.6/dist-packages (from bravado->neptune-client==0.4.132) (5.17.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from bravado->neptune-client==0.4.132) (3.13)\n",
            "Requirement already satisfied: monotonic in /usr/local/lib/python3.6/dist-packages (from bravado->neptune-client==0.4.132) (1.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from bravado->neptune-client==0.4.132) (3.7.4.3)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.6/dist-packages (from bravado->neptune-client==0.4.132) (3.17.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython>=2.0.8->neptune-client==0.4.132) (4.0.5)\n",
            "Requirement already satisfied: swagger-spec-validator>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from bravado-core>=5.16.1->bravado->neptune-client==0.4.132) (2.7.3)\n",
            "Requirement already satisfied: jsonref in /usr/local/lib/python3.6/dist-packages (from bravado-core>=5.16.1->bravado->neptune-client==0.4.132) (0.2)\n",
            "Requirement already satisfied: jsonschema[format]>=2.5.1 in /usr/local/lib/python3.6/dist-packages (from bravado-core>=5.16.1->bravado->neptune-client==0.4.132) (2.6.0)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython>=2.0.8->neptune-client==0.4.132) (3.0.5)\n",
            "Requirement already satisfied: webcolors; extra == \"format\" in /usr/local/lib/python3.6/dist-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune-client==0.4.132) (1.11.1)\n",
            "Requirement already satisfied: strict-rfc3339; extra == \"format\" in /usr/local/lib/python3.6/dist-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune-client==0.4.132) (0.7)\n",
            "Requirement already satisfied: rfc3987; extra == \"format\" in /usr/local/lib/python3.6/dist-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune-client==0.4.132) (1.3.8)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.2.0+cu92\n",
            "  Using cached https://download.pytorch.org/whl/cu92/torch-1.2.0%2Bcu92-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Collecting torchvision==0.4.0+cu92\n",
            "  Using cached https://download.pytorch.org/whl/cu92/torchvision-0.4.0%2Bcu92-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.2.0+cu92) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.0+cu92) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.0+cu92) (1.15.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.8.0a0+unknown\n",
            "    Uninstalling torch-1.8.0a0+unknown:\n",
            "      Successfully uninstalled torch-1.8.0a0+unknown\n",
            "  Found existing installation: torchvision 0.9.0a0+59d3af5\n",
            "    Uninstalling torchvision-0.9.0a0+59d3af5:\n",
            "      Successfully uninstalled torchvision-0.9.0a0+59d3af5\n",
            "Successfully installed torch-1.2.0+cu92 torchvision-0.4.0+cu92\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Project(aaronjosephmathew/sandbox)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bZggvZF8J-h"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "%matplotlib inline\r\n",
        "sns.set(color_codes=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og_gdMMB3t6R"
      },
      "source": [
        "# Obtaining the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS_rIrhm3tSs"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/training.1600000.processed.noemoticon.csv',header=None,error_bad_lines=False,engine='python')\r\n",
        "df.columns=['Sentiment', 'id', 'Date', 'Query', 'User', 'Tweet']\r\n",
        "df = df.drop(columns=['id', 'Date', 'Query', 'User'], axis=1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgGzmfV93YuD"
      },
      "source": [
        "df['Sentiment'] = df.Sentiment.replace(4,1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "eksCM-9t8i16",
        "outputId": "917f5f10-3881-4a66-a15a-a8df0c4d9b1a"
      },
      "source": [
        "import re\r\n",
        "\r\n",
        "hashtags = re.compile(r\"^#\\S+|\\s#\\S+\")\r\n",
        "mentions = re.compile(r\"^@\\S+|\\s@\\S+\")\r\n",
        "urls = re.compile(r\"https?://\\S+\")\r\n",
        "\r\n",
        "def process_text(text):\r\n",
        "  text = re.sub(r'http\\S+', '', text)\r\n",
        "  text = hashtags.sub(' hashtag', text)\r\n",
        "  text = mentions.sub(' entity', text)\r\n",
        "  return text.strip().lower()\r\n",
        "  \r\n",
        "df['Tweet'] = df.Tweet.apply(process_text)\r\n",
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>entity  - awww, that's a bummer.  you shoulda ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>entity i dived many times for the ball. manage...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>entity no, it's not behaving at all. i'm mad. ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentiment                                              Tweet\n",
              "0          0  entity  - awww, that's a bummer.  you shoulda ...\n",
              "1          0  is upset that he can't update his facebook by ...\n",
              "2          0  entity i dived many times for the ball. manage...\n",
              "3          0     my whole body feels itchy and like its on fire\n",
              "4          0  entity no, it's not behaving at all. i'm mad. ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnjKJ1PZ8mOV"
      },
      "source": [
        "labels = df.Sentiment.values\r\n",
        "text = df.Tweet.values"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuOFVTYfBTpX"
      },
      "source": [
        "# Code to check if GPU is being utilised\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tltEV5jhEK6n",
        "outputId": "34bb933d-4ab7-4d21-c19c-f7732b891887",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(torch.__version__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.2.0+cu92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dew-5OGVBYS1",
        "outputId": "82c98baa-6ccc-4de7-f088-f744b7b4a7e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if torch.cuda.is_available():  \r\n",
        "  dev = \"cuda:0\" \r\n",
        "else:  \r\n",
        "  dev = \"cpu\"  \r\n",
        "\r\n",
        "print(dev)\r\n",
        "print(\"IF CPU is shown above, CUDA is not enabled\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "IF CPU is shown above, CUDA is not enabled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfuIIgG882si"
      },
      "source": [
        "# Model Development"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v1Kd5dT80o_",
        "outputId": "9a4a1bd0-b703-4c74-b408-b765a2cedc82"
      },
      "source": [
        "from transformers import BertTokenizer,BertForSequenceClassification,AdamW\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case = True)\r\n",
        "input_ids = []\r\n",
        "attention_mask = []\r\n",
        "for i in text:\r\n",
        "    encoded_data = tokenizer.encode_plus(\r\n",
        "    i,\r\n",
        "    add_special_tokens=True,\r\n",
        "    max_length=64,\r\n",
        "    pad_to_max_length = True,\r\n",
        "    return_attention_mask= True,\r\n",
        "    return_tensors='pt')\r\n",
        "    input_ids.append(encoded_data['input_ids'])\r\n",
        "    attention_mask.append(encoded_data['attention_mask'])\r\n",
        "input_ids = torch.cat(input_ids,dim=0)\r\n",
        "attention_mask = torch.cat(attention_mask,dim=0)\r\n",
        "labels = torch.tensor(labels)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2143: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuJQL64-8-y2"
      },
      "source": [
        "from torch.utils.data import DataLoader,SequentialSampler,RandomSampler,TensorDataset,random_split"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Geujauyu9Cuv",
        "outputId": "3fcb1b97-dd25-4409-8006-f55c103d99d1"
      },
      "source": [
        "dataset = TensorDataset(input_ids,attention_mask,labels)\r\n",
        "train_size = int(0.8*len(dataset))\r\n",
        "val_size = len(dataset) - train_size\r\n",
        "\r\n",
        "train_dataset,val_dataset = random_split(dataset,[train_size,val_size])\r\n",
        "\r\n",
        "print('Training Size - ',train_size)\r\n",
        "print('Validation Size - ',val_size)\r\n",
        "train_dl = DataLoader(train_dataset,sampler = RandomSampler(train_dataset),\r\n",
        "                     batch_size = 32)\r\n",
        "val_dl = DataLoader(val_dataset,sampler = SequentialSampler(val_dataset),\r\n",
        "                     batch_size = 32)\r\n",
        "\r\n",
        "len(train_dl),len(val_dl)\r\n",
        "\r\n",
        "model = BertForSequenceClassification.from_pretrained(\r\n",
        "'bert-base-uncased',\r\n",
        "num_labels = 2,\r\n",
        "output_attentions = False,\r\n",
        "output_hidden_states = False)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Size -  1280000\n",
            "Validation Size -  320000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yz4ILbG9F_Q"
      },
      "source": [
        "import random\r\n",
        "\r\n",
        "seed_val = 17\r\n",
        "random.seed(seed_val)\r\n",
        "np.random.seed(seed_val)\r\n",
        "torch.manual_seed(seed_val)\r\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXr_z94L9PmP",
        "outputId": "f8c064c2-1573-44c0-f040-e8be3ded553b"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "model.to(device)\r\n",
        "print(device)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owkULzLx9SLf"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),lr = 2e-5,eps=1e-8)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec42cO1W9VO8"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\r\n",
        "epochs = 1\r\n",
        "total_steps = len(train_dl)*epochs\r\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=0,\r\n",
        "                                           num_training_steps=total_steps)\r\n",
        "\r\n",
        "def accuracy(preds,labels):\r\n",
        "  pred_flat = np.argmax(preds,axis=1).flatten()\r\n",
        "  label_flat = labels.flatten()\r\n",
        "  return np.sum(pred_flat==label_flat)/len(label_flat)\r\n",
        "\r\n",
        "def evaluate(dataloader_test):\r\n",
        "  model.eval()\r\n",
        "  loss_val_total = 0\r\n",
        "  predictions,true_vals = [],[]\r\n",
        "  for batch in dataloader_test:\r\n",
        "      batch = tuple(b.to(device) for b in batch)\r\n",
        "      inputs = {\r\n",
        "          'input_ids':batch[0],\r\n",
        "          'attention_mask': batch[1],\r\n",
        "          'labels': batch[2]\r\n",
        "      }\r\n",
        "      with torch.no_grad():\r\n",
        "          outputs = model(**inputs)\r\n",
        "      loss = outputs[0]\r\n",
        "      logits = outputs[1]\r\n",
        "      loss_val_total += loss.item()\r\n",
        "      logits = logits.detach().cpu().numpy()\r\n",
        "      label_ids = inputs['labels'].cpu().numpy()\r\n",
        "      predictions.append(logits)\r\n",
        "      true_vals.append(label_ids)\r\n",
        "  loss_val_avg = loss_val_total / len(dataloader_test)\r\n",
        "  predictions = np.concatenate(predictions,axis=0)\r\n",
        "  true_vals = np.concatenate(true_vals,axis=0)\r\n",
        "  return loss_val_avg,predictions,true_vals\r\n",
        "\r\n",
        "if torch.cuda.is_available():  \r\n",
        "  dev = \"cuda:0\" \r\n",
        "else:  \r\n",
        "  dev = \"cpu\"  \r\n",
        "device = torch.device(dev)  \r\n",
        "a = torch.zeros(4,3)    \r\n",
        "a = a.to(device)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "r0eVAAVj9iAJ",
        "outputId": "99b1f587-858d-4b4d-995d-0d3b0db29863"
      },
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\r\n",
        "!pip3 install torchvision"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==0.4.1\n",
            "\u001b[?25l  Downloading http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl (512.6MB)\n",
            "\u001b[K     |████████████████████████████████| 512.6MB 2.3MB/s \n",
            "\u001b[31mERROR: torchvision 0.4.0+cu92 has requirement torch==1.2.0, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.61 has requirement torch>=1.0.0, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Found existing installation: torch 1.2.0+cu92\n",
            "    Uninstalling torch-1.2.0+cu92:\n",
            "      Successfully uninstalled torch-1.2.0+cu92\n",
            "Successfully installed torch-0.4.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.0+cu92)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Collecting torch==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/57/d5cceb0799c06733eefce80c395459f28970ebb9e896846ce96ab579a3f1/torch-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n",
            "\u001b[K     |████████████████████████████████| 748.9MB 22kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.19.5)\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 0.4.1\n",
            "    Uninstalling torch-0.4.1:\n",
            "      Successfully uninstalled torch-0.4.1\n",
            "Successfully installed torch-1.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "e8093e9097904a80b333ac8660bf8ba2",
            "ca15aa74aed34494a003e075e0b563fe",
            "6a859e339aae4026ae78d3e217391b86",
            "541be8d5999e49eb9a042f0db6ad9840",
            "f92fe93b671a424e8128677545b94a9a",
            "4ce0064975634ee5abd8cbaed76edac6",
            "904be8f7f5d94124b73d85df97fbc635",
            "a448870a16014eb19f52883018fbf676",
            "b79453e7bf224ffbbee0695ed6671f0a",
            "2ceb9d8e716641cabcabf57aedc83be1",
            "e03ede94e4be447f88be066ffd8024a1",
            "5000ac9f1a9747629d554d2426f6df1f",
            "ee10b5bbc9d445b0b98f1e84f177e968",
            "9ebd7160f75a474da11326894afb0a50",
            "a884708730b84e709d51cbb454bfa795",
            "4a8b2e67fdf14715bd325f7d7dce5be2"
          ]
        },
        "id": "0OjHEmue9lci",
        "outputId": "b10b5d78-e3c4-455a-b8e3-760bf9e4d0c7"
      },
      "source": [
        "from tqdm.notebook import tqdm\r\n",
        "torch.cuda.empty_cache()\r\n",
        "for epoch in tqdm(range(1, epochs+1)):\r\n",
        "    \r\n",
        "    model.train()\r\n",
        "    \r\n",
        "    loss_train_total = 0\r\n",
        "\r\n",
        "    progress_bar = tqdm(train_dl, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\r\n",
        "    for batch in progress_bar:\r\n",
        "\r\n",
        "        model.zero_grad()\r\n",
        "        \r\n",
        "        batch = tuple(b.to(device) for b in batch)\r\n",
        "        \r\n",
        "        inputs = {'input_ids':      batch[0],\r\n",
        "                  'attention_mask': batch[1],\r\n",
        "                  'labels':         batch[2],\r\n",
        "                 }       \r\n",
        "\r\n",
        "        outputs = model(**inputs)\r\n",
        "        \r\n",
        "        loss = outputs[0]\r\n",
        "        loss_train_total += loss.item()\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n",
        "\r\n",
        "        optimizer.step()\r\n",
        "        scheduler.step()\r\n",
        "        \r\n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\r\n",
        "         \r\n",
        "        \r\n",
        "    tqdm.write(f'\\nEpoch {epoch}')\r\n",
        "    \r\n",
        "    loss_train_avg = loss_train_total/len(train_dl)            \r\n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\r\n",
        "    \r\n",
        "    val_loss, predictions, true_vals = evaluate(val_dl)\r\n",
        "    val_acc = accuracy(predictions, true_vals)\r\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\r\n",
        "    tqdm.write(f'Accuracy: {val_acc}')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8093e9097904a80b333ac8660bf8ba2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b79453e7bf224ffbbee0695ed6671f0a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=40000.0, style=ProgressStyle(description_wi…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Epoch 1\n",
            "Training loss: 0.3235170240367763\n",
            "Validation loss: 0.2971883612576872\n",
            "Accuracy: 0.87431875\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9PtBQko9ox1",
        "outputId": "41988370-dde0-4380-d603-d967bfbdd5b6"
      },
      "source": [
        "output_dir = './'\r\n",
        "model_to_save = model.module if hasattr(model, 'module') else model\r\n",
        "model_to_save.save_pretrained(output_dir)\r\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./tokenizer_config.json',\n",
              " './special_tokens_map.json',\n",
              " './vocab.txt',\n",
              " './added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INHOpIM79raF",
        "outputId": "a71786a1-6555-45ff-f00f-e992a0f473f4"
      },
      "source": [
        "from transformers import BertTokenizer,BertForSequenceClassification\r\n",
        "import torch\r\n",
        "# Load the BERT tokenizer.\r\n",
        "print('Loading BERT tokenizer...')\r\n",
        "output_dir = './'\r\n",
        "tokenizer = BertTokenizer.from_pretrained(output_dir)\r\n",
        "model_loaded = BertForSequenceClassification.from_pretrained(output_dir)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k3QyfQn9tmg"
      },
      "source": [
        "def Sentiment(sent):\r\n",
        "    output_dir = './'\r\n",
        "    tokenizer = BertTokenizer.from_pretrained(output_dir)\r\n",
        "    model_loaded = BertForSequenceClassification.from_pretrained(output_dir)\r\n",
        "    encoded_dict = tokenizer.encode_plus(\r\n",
        "                        sent, \r\n",
        "                        add_special_tokens = True,\r\n",
        "                        max_length = 64,\r\n",
        "                        pad_to_max_length = True,\r\n",
        "                        return_attention_mask = True,\r\n",
        "                        return_tensors = 'pt',\r\n",
        "                   )\r\n",
        "        \r\n",
        "    input_id = encoded_dict['input_ids']\r\n",
        "\r\n",
        "    attention_mask = encoded_dict['attention_mask']\r\n",
        "    input_id = torch.LongTensor(input_id)\r\n",
        "    attention_mask = torch.LongTensor(attention_mask)\r\n",
        "\r\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "    model_loaded = model_loaded.to(device)\r\n",
        "    input_id = input_id.to(device)\r\n",
        "    attention_mask = attention_mask.to(device)\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "        outputs = model_loaded(input_id, token_type_ids=None, attention_mask=attention_mask)\r\n",
        "\r\n",
        "    logits = outputs[0]\r\n",
        "    index = logits.argmax()\r\n",
        "    return index"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQbavxcaE531"
      },
      "source": [
        "ans = Sentiment('i want to die')\r\n",
        "\r\n",
        "if ans == 1:\r\n",
        "    print(\"Positive\")\r\n",
        "else:\r\n",
        "    print(\"Negative\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}